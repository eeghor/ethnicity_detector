{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from string import punctuation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from unidecode import unidecode\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans, MeanShift\n",
    "from ethnicity_features import (Selector, WordCount, NameLength, \n",
    "                                FirstLast, DictFirstNameFeatures, \n",
    "                                VowelsShare, ModelTransformer, MakeDense)\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EP:\n",
    "    \n",
    "    def __init__(self, ethnicity):  \n",
    "        \n",
    "        assert ethnicity in ('iranian polish italian german japanese vietnamese'\n",
    "                             ' portuguese fijian indian croatian greek'\n",
    "                             ' serbian spanish korean thai turkish' \n",
    "                             ' english cambodian russian bosnian chinese').split(), f'incorrect ethnicity: {ethnicity}!'\n",
    "        \n",
    "        datafile = f'/Users/ik/Data/names/training-{ethnicity}.csv'\n",
    "        self.target_col = f'is_{ethnicity}'\n",
    "        \n",
    "        self.data = pd.read_csv(datafile).sample(frac=1.)\n",
    "        self.data['full_name'] = self.data['full_name'].apply(lambda _: unidecode(_))\n",
    "        \n",
    "        assert self.target_col in self.data.columns, f'there is no {self.target_col} in data file!'  \n",
    "        \n",
    "        try:\n",
    "            self.NODOUBT_FIRST_NAMES = list({line.strip() for line in open(f'/Users/ik/Data/names/real_{ethnicity}.txt','r').readlines() if line.strip()})\n",
    "        except:\n",
    "            self.NODOUBT_FIRST_NAMES = []\n",
    "#         print(self.NODOUBT_FIRST_NAMES)\n",
    "        \n",
    "    def add_nodoubt_names(self):\n",
    "        \n",
    "        print(f'adding {len(self.NODOUBT_FIRST_NAMES)} first names..')\n",
    "        \n",
    "        self.data = pd.concat([self.data, pd.DataFrame({'full_name': self.NODOUBT_FIRST_NAMES, \n",
    "                                                        self.target_col: [1]*len(self.NODOUBT_FIRST_NAMES)})], \n",
    "                              ignore_index=True).sample(frac=1.)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('select_fullname', Selector(col_name='full_name')), ('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('char_level', CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True...restarts_optimizer=1, optimizer='fmin_l_bfgs_b',\n",
       "             random_state=None, warm_start=False))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    ETHN = 'chinese'\n",
    "    \n",
    "    ic = EP(ETHN)\n",
    "#     .add_nodoubt_names()\n",
    "    \n",
    "    # split into the training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(ic.data.drop([ic.target_col], axis=1), \n",
    "                                                        ic.data[ic.target_col],  test_size=0.25, \n",
    "                                                        random_state=391, stratify=ic.data[ic.target_col])\n",
    "    \n",
    "\n",
    "    pipe = Pipeline([('select_fullname', Selector('full_name')),  # df with 1 column\n",
    "                     ('features', FeatureUnion(\n",
    "                         [('char_level', CountVectorizer(strip_accents='ascii', analyzer='char', \n",
    "                                                          ngram_range=(2, 4))),\n",
    "                          ('word_level', CountVectorizer(strip_accents='ascii', analyzer='word',\n",
    "                                                       ngram_range=(1,3))),\n",
    "                          ('word_count', WordCount()),\n",
    "                          ('dict_fname', DictFirstNameFeatures(ic.NODOUBT_FIRST_NAMES)),\n",
    "                          ('vow_share', VowelsShare()),\n",
    "                          ('full_name_length', NameLength()),  \n",
    "                          ('firstlast', FirstLast())])),\n",
    "#                               transformer_weights={\n",
    "#                                             'char_level': 0.8,\n",
    "#                                             'word_level': 0.5,\n",
    "#                                             'word_lengths': 1.0,})),\n",
    "#                          ])),\n",
    "                     ('normalise', Normalizer()),\n",
    "#                      ('pca', TruncatedSVD(n_components=120)),\n",
    "#                      ('clf', VotingClassifier(estimators=[('sgd', SGDClassifier(max_iter=1000)),\n",
    "#                                                            ('rf', RandomForestClassifier(class_weight='balanced')),\n",
    "#                                                             ('svc', SVC(C=0.0001)),\n",
    "#                                                              ('abst', AdaBoostClassifier(n_estimators=200)),\n",
    "#                                                              ('gb', GradientBoostingClassifier(n_estimators=200)),\n",
    "#                                                          ('kmeans', KMeans(n_clusters=2))], \n",
    "#                                                                     voting='hard'))])\n",
    "                     ('clf', FeatureUnion([('sgd', ModelTransformer(SGDClassifier(max_iter=1000))),\n",
    "                                             ('rf', ModelTransformer(RandomForestClassifier(class_weight='balanced', n_estimators=200))),\n",
    "                                             ('kmeans', ModelTransformer(KMeans(n_clusters=2))),\n",
    "                                             ('gb', ModelTransformer(GradientBoostingClassifier(n_estimators=200))),\n",
    "                                             ('abst', ModelTransformer(AdaBoostClassifier(n_estimators=200))),\n",
    "                                             ('svc', ModelTransformer(SVC(C=0.0001))),\n",
    "                                             ('mlpc', ModelTransformer(MLPClassifier())),\n",
    "                                             ('gau', ModelTransformer(ExtraTreesClassifier(n_estimators=40)))\n",
    "                                            ])),\n",
    "                     ('final_cls',GaussianProcessClassifier(n_restarts_optimizer=1) )])\n",
    "    \n",
    "#     param_grid = {\n",
    "#         'features__transformer_weights': [{'char_level': 0.2,\n",
    "#                                                      'word_level': 0.1,\n",
    "#                                                      'word_count':0.4,\n",
    "#                                                     'full_name_length': 0.5}, \n",
    "#                                                    {'char_level': 0.9,\n",
    "#                                                      'word_level': 0.2,\n",
    "#                                                      'word_lengths':0.9,\n",
    "#                                                    'full_name_length': 0.3},\n",
    "#                                                    {'char_level': 0.9,\n",
    "#                                                      'word_level': 0.3,\n",
    "#                                                      'word_count':0.2,\n",
    "#                                                    'full_name_length': 0.7}],\n",
    "#                     'clf__sgd__loss': ['modified_huber'], # also 'hinge', 'perceptron', 'log'\n",
    "#                     'clf__sgd__penalty': ['l2'],  # 'elasticnet', 'l1'\n",
    "#                     'clf__rf__n_estimators': [100, 200, 300],\n",
    "#                     'clf__rf__max_depth': [None, 2, 3],\n",
    "#                     'clf__svc__C': [1e-6, 1e-5, 1e-4, 1e-2, 1.]}  # default is 1.\n",
    "#                  'pca__n_components': [30, 120, 400]}\n",
    "    \n",
    "#     grid_search = GridSearchCV(pipe, param_grid=param_grid, verbose=10)\n",
    "pipe.fit(X_train, y_train)\n",
    "    \n",
    "#     grid_search.fit(X_train, y_train)\n",
    "    \n",
    "#     joblib.dump(grid_search.best_estimator_, f'{ETHN}_model.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      2400\n",
      "          1       0.97      0.98      0.98      2198\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame({'full_name': ['han walota', 'xi','babak', 'igor souza', 'yash patel', 'david perron',\n",
    "                                        'andrzej woods','otto floms', 'suzuki', 'iloilovatu', \n",
    "                                        'edilson', 'kawasaki','silva', 'james tran', \n",
    "                                        'bo nguyen', 'zlatan ibrahimovic', 'ronaldo barbosa', 'natalia klanchinkova', \n",
    "                                        'bob', 'keresi right','kalara',  'kona reed', 'andreas vlachos', 'con', 'nemanja vidic']})\n",
    "\n",
    "test_data['prediction'] = pipe.predict(test_data)\n",
    "test_data['prediction'] = test_data['prediction'].apply(lambda _: 'yes' if _ else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORINNE SUE TIN predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "MAN FRED predicted 0 but it is 1 // prob of NO: 0.603, prob of YES: 0.397\n",
      "SHEWKET YALQUN predicted 0 but it is 1 // prob of NO: 0.784, prob of YES: 0.216\n",
      "NATASHA TSUI PO predicted 0 but it is 1 // prob of NO: 0.784, prob of YES: 0.216\n",
      "TERRENCE SUM predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "BOU LAM predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "THANH LAM predicted 1 but it is 0 // prob of NO: 0.14, prob of YES: 0.86\n",
      "ALEXANDRA LAU predicted 0 but it is 1 // prob of NO: 0.784, prob of YES: 0.216\n",
      "CHAN MILLY predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "TONG DUC AN predicted 1 but it is 0 // prob of NO: 0.002, prob of YES: 0.998\n",
      "CASSANDRA SHI predicted 0 but it is 1 // prob of NO: 0.949, prob of YES: 0.051\n",
      "MENG BUNLO predicted 1 but it is 0 // prob of NO: 0.216, prob of YES: 0.784\n",
      "YOSEI OTSU predicted 1 but it is 0 // prob of NO: 0.411, prob of YES: 0.589\n",
      "SENG BOTUM predicted 1 but it is 0 // prob of NO: 0.216, prob of YES: 0.784\n",
      "BENTINCK GUO predicted 0 but it is 1 // prob of NO: 0.784, prob of YES: 0.216\n",
      "PRISCILLIA WONG WONG predicted 0 but it is 1 // prob of NO: 0.566, prob of YES: 0.434\n",
      "BAE KI-JONG predicted 1 but it is 0 // prob of NO: 0.49, prob of YES: 0.51\n",
      "SAN CHAMRONG predicted 1 but it is 0 // prob of NO: 0.002, prob of YES: 0.998\n",
      "ERTEN ERSU predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "BOU SARUN predicted 1 but it is 0 // prob of NO: 0.411, prob of YES: 0.589\n",
      "SO KHUN predicted 1 but it is 0 // prob of NO: 0.216, prob of YES: 0.784\n",
      "KEN IWAO predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "RATU DAU predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "SHUK KWAN TERESA FUNG predicted 0 but it is 1 // prob of NO: 0.892, prob of YES: 0.108\n",
      "HUN SEN predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "HA VU EM predicted 1 but it is 0 // prob of NO: 0.411, prob of YES: 0.589\n",
      "BRADFORD LAU predicted 0 but it is 1 // prob of NO: 0.949, prob of YES: 0.051\n",
      "TAPUNUU AH CHEUNG predicted 0 but it is 1 // prob of NO: 0.892, prob of YES: 0.108\n",
      "CHULI predicted 1 but it is 0 // prob of NO: 0.411, prob of YES: 0.589\n",
      "ALEXANDER HAO predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "TANG MANYANG predicted 1 but it is 0 // prob of NO: 0.002, prob of YES: 0.998\n",
      "HEINZ LANGE predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "OLEG LANIN predicted 1 but it is 0 // prob of NO: 0.333, prob of YES: 0.667\n",
      "OH JIN-KWANG predicted 1 but it is 0 // prob of NO: 0.396, prob of YES: 0.604\n",
      "SVANG SAMNANG predicted 1 but it is 0 // prob of NO: 0.223, prob of YES: 0.777\n",
      "YINGYONG BUD-NGAM predicted 1 but it is 0 // prob of NO: 0.49, prob of YES: 0.51\n",
      "ELIZABETH CAO predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "LEE HOI-CHANG predicted 1 but it is 0 // prob of NO: 0.327, prob of YES: 0.673\n",
      "MIRANDA TAI predicted 0 but it is 1 // prob of NO: 0.784, prob of YES: 0.216\n",
      "PATRICK WAI SAFE predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "STEVIE HOANG predicted 1 but it is 0 // prob of NO: 0.223, prob of YES: 0.777\n",
      "LILLO predicted 1 but it is 0 // prob of NO: 0.411, prob of YES: 0.589\n",
      "VANNA EUNG predicted 1 but it is 0 // prob of NO: 0.327, prob of YES: 0.673\n",
      "XENI PAXINOU predicted 1 but it is 0 // prob of NO: 0.059, prob of YES: 0.941\n",
      "LEE EUL-YONG predicted 1 but it is 0 // prob of NO: 0.327, prob of YES: 0.673\n",
      "CHLOE DAO predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "TONG HUDUDAER predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "LIN PINAULT predicted 0 but it is 1 // prob of NO: 0.784, prob of YES: 0.216\n",
      "BEN HENEGHAN predicted 1 but it is 0 // prob of NO: 0.411, prob of YES: 0.589\n",
      "NUTH PITU predicted 1 but it is 0 // prob of NO: 0.14, prob of YES: 0.86\n",
      "NGIM YENG predicted 1 but it is 0 // prob of NO: 0.223, prob of YES: 0.777\n",
      "STEFANIE HUNG predicted 0 but it is 1 // prob of NO: 0.621, prob of YES: 0.379\n",
      "HU HUDUBUHUA predicted 0 but it is 1 // prob of NO: 0.541, prob of YES: 0.459\n",
      "RA HYE-IN predicted 1 but it is 0 // prob of NO: 0.333, prob of YES: 0.667\n",
      "HA GANG-SAN predicted 1 but it is 0 // prob of NO: 0.333, prob of YES: 0.667\n",
      "CAO XUAN THANG predicted 1 but it is 0 // prob of NO: 0.02, prob of YES: 0.98\n",
      "AY KHORN predicted 1 but it is 0 // prob of NO: 0.333, prob of YES: 0.667\n",
      "YANG DONG-WON predicted 1 but it is 0 // prob of NO: 0.396, prob of YES: 0.604\n",
      "SHU MOGI predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "TAT TSIAN CHIAM predicted 0 but it is 1 // prob of NO: 0.784, prob of YES: 0.216\n",
      "BIN CHHIN predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "CHARLIE CHAN FOON predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "MARINA SHI predicted 0 but it is 1 // prob of NO: 0.784, prob of YES: 0.216\n",
      "JOSEPHINE YAP predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "JEFF KING predicted 1 but it is 0 // prob of NO: 0.223, prob of YES: 0.777\n",
      "JIE SMITH predicted 0 but it is 1 // prob of NO: 0.949, prob of YES: 0.051\n",
      "OLIVIA SUEN predicted 0 but it is 1 // prob of NO: 0.826, prob of YES: 0.174\n",
      "DIL RAJU predicted 1 but it is 0 // prob of NO: 0.057, prob of YES: 0.943\n",
      "YEO OK predicted 1 but it is 0 // prob of NO: 0.183, prob of YES: 0.817\n",
      "MELISSA LUM predicted 0 but it is 1 // prob of NO: 0.949, prob of YES: 0.051\n",
      "SLEH SEN predicted 1 but it is 0 // prob of NO: 0.216, prob of YES: 0.784\n",
      "LAM TI PHONG predicted 1 but it is 0 // prob of NO: 0.396, prob of YES: 0.604\n",
      "JUAN MAGAN predicted 1 but it is 0 // prob of NO: 0.057, prob of YES: 0.943\n",
      "LIA FRANCA predicted 1 but it is 0 // prob of NO: 0.286, prob of YES: 0.714\n",
      "ERPAN EZIMJAN predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "LIM HOU HOCK predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "KATT HSIEH predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "VAN CAO predicted 1 but it is 0 // prob of NO: 0.057, prob of YES: 0.943\n",
      "YAN CHIZHKOV predicted 1 but it is 0 // prob of NO: 0.057, prob of YES: 0.943\n",
      "RUBY LI TEOH predicted 0 but it is 1 // prob of NO: 0.541, prob of YES: 0.459\n",
      "GULBIN SU predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "CAN OKUYUCU predicted 1 but it is 0 // prob of NO: 0.411, prob of YES: 0.589\n",
      "EREN TOZLU predicted 1 but it is 0 // prob of NO: 0.14, prob of YES: 0.86\n",
      "BELINDA HUA predicted 0 but it is 1 // prob of NO: 0.949, prob of YES: 0.051\n",
      "RAIMA SEN predicted 1 but it is 0 // prob of NO: 0.333, prob of YES: 0.667\n",
      "CHUN YIU ELDEN CHAN predicted 0 but it is 1 // prob of NO: 0.863, prob of YES: 0.137\n",
      "GOLO MANN predicted 1 but it is 0 // prob of NO: 0.333, prob of YES: 0.667\n",
      "CHO YE-CHAN predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "YU DONG-CHUN predicted 1 but it is 0 // prob of NO: 0.015, prob of YES: 0.985\n",
      "ROUS HAI predicted 1 but it is 0 // prob of NO: 0.001, prob of YES: 0.999\n",
      "JOHANNA CHIN predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "DOROTHY HE predicted 0 but it is 1 // prob of NO: 0.999, prob of YES: 0.001\n",
      "KORNG HEANG predicted 1 but it is 0 // prob of NO: 0.396, prob of YES: 0.604\n",
      "MAX SPRANG predicted 1 but it is 0 // prob of NO: 0.223, prob of YES: 0.777\n"
     ]
    }
   ],
   "source": [
    "for t in zip(X_test.values, pipe.predict(X_test), y_test.values, pipe.predict_proba(X_test)):\n",
    "    if t[1] != t[2]:\n",
    "        print(f'{t[0][0].upper()} predicted {t[1]} but it is {t[2]} // prob of NO: {round(t[3][0],3)}, prob of YES: {round(t[3][1],3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.best_estimator_\n",
    "joblib.dump(pipe, f'{ETHN}_model.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
