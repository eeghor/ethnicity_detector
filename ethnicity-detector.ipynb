{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from unidecode import unidecode\n",
    "from string import ascii_lowercase\n",
    "import sqlalchemy as sa\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableCollector(object):\n",
    "    \n",
    "    def __init__(self, driver='pyodbc'):\n",
    "        \n",
    "        self.DRIVER_NAME = driver\n",
    "        \n",
    "        assert self.DRIVER_NAME in ['pyodbc', 'pymssql'], \"wrong driver name - choose pyodbc or pymssql\"\n",
    "        \n",
    "        try:\n",
    "            self.SERVER, self.USER, self.PORT, self.PWD, self.DRIVER, self.DB_NAME = \\\n",
    "            [line.split(\"=\")[-1].strip() for line in open(\"config/connection.ini\", 'r').readlines() if line.strip()]          \n",
    "        except:\n",
    "            print(\"problem with configuration file, exiting..\")\n",
    "            sys.exit(0)\n",
    "            \n",
    "    def connect(self):\n",
    "        \n",
    "        self.CONNSTR = 'mssql+{}://{}:{}@{}:{}/{}'.format(self.DRIVER_NAME, self.USER, self.PWD, \n",
    "                                                          self.SERVER, self.PORT, self.DB_NAME)\n",
    "        \n",
    "        if self.DRIVER_NAME == 'pyodbc':\n",
    "            import pyodbc\n",
    "            self.CONNSTR += '?driver=' + self.DRIVER\n",
    "        elif self.DRIVER_NAME == 'pymssql':\n",
    "            import pymssql\n",
    "            \n",
    "        eng = sa.create_engine(self.CONNSTR)\n",
    "        self.CONNECTION = eng.connect()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_customers(self):\n",
    "        \n",
    "        self.TODAY = datetime.now().strftime(\"%Y%m%d\")\n",
    "        pick_customers_qry = \"\"\"\n",
    "                SELECT [CustomerID] as [cust_id],\n",
    "                RTRIM(LTRIM(LOWER(ISNULL([FirstName],'')))) + ' ' +\n",
    "                RTRIM(LTRIM(LOWER(ISNULL([MiddleName],'')))) + ' ' +\n",
    "                RTRIM(LTRIM(LOWER(ISNULL([LastName],'')))) as [full_name]\n",
    "                FROM [DWSales].[dbo].[tbl_LotusCustomer]\n",
    "                where ([CustomerListID] = 2) and ([ModifiedDate] = '\"\"\" + self.TODAY + \"')\"\n",
    "        \n",
    "        self.TODAYS_CUSTOMERS = pd.read_sql(pick_customers_qry, self.CONNECTION, dtype=str)\n",
    "        \n",
    "        self.IDS_IN_TABLE = set(pd.read_sql(\"SELECT [CustomerID] FROM dbo.CustomerEthnicities;\", \n",
    "                                            self.CONNECTION, dtype=str)[\"CustomerID\"])    \n",
    "        return self\n",
    "    \n",
    "    def upload_ethnicities(self, df_ethn):\n",
    "        \n",
    "        self.IDS_TO_UPDATE = self.IDS_IN_TABLE & set(df_ethn.index)\n",
    "        self.IDS_TO_APPEND = set(df_ethn.index) - self.IDS_TO_UPDATE\n",
    "        # note: 'append': if table exists, insert data. Create if does not exist\n",
    "        df_ethn.loc[df_ethn.cust_id.isin(self.IDS_TO_APPEND), :].to_sql('dbo.CustomerEthnicities', \n",
    "                                                                        self.CONNECTION, if_exists='append')\n",
    "        if self.IDS_TO_UPDATE:\n",
    "            \n",
    "            upd_dict = defaultdict(lambda: defaultdict(str))\n",
    "            \n",
    "            df_to_update = pd.read_sql(\"SELECT * FROM dbo.CustomerEthnicities where CustomerID in \" + \"(\" + \",\".join(self.IDS_TO_UPDATE) + \");\", \n",
    "                                            self.CONNECTION, dtype=str)\n",
    "            for row in df_to_update.iterrows():\n",
    "                available_ethnicities = set(row[1].Ethnicity.split(\"|\"))\n",
    "                updated_ethnicities = \"|\".join(available_ethnicities | set(df_ethn.loc[df_ethn.index == row[0], \"Ethnicity\"].values[0].split(\"|\")))\n",
    "                upd_dict[row[0]] = {\"Ethnicity\": updated_ethnicities}\n",
    "            \n",
    "            upd_df = pd.DataFrame.from_dict(upd_dict, orient='index').reset_index().rename(columns={\"index\": \"CustomerID\"})\n",
    "            \n",
    "            upd_df.loc[upd_df, :].to_sql('dbo.CustomerEthnicities', self.CONNECTION, if_exists='append')\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EthnicityDetector(object):\n",
    "    \n",
    "    def __init__(self, df, ethnicity_list):\n",
    "        \n",
    "        self.DATA_DIR = \"/Users/ik/Data/\"\n",
    "        self.NAME_DATA_DIR = self.DATA_DIR + \"names/\"\n",
    "        self.ethnicity_list = ethnicity_list\n",
    "        self.input_df = df\n",
    "        \n",
    "        # load name and surname databases\n",
    "        self.name_dict = json.load(open(self.NAME_DATA_DIR + \"names_26092017.json\", \"r\"))\n",
    "        self.surname_dict = json.load(open(self.NAME_DATA_DIR + \"surnames_26092017.json\", \"r\"))\n",
    "        self.surname_ending_dict = json.load(open(self.NAME_DATA_DIR + \"surname_endings_06102017.json\", \"r\"))\n",
    "        self.deciders = {\"arabic\": \"name_and_surname\", \"italian\": \"name_and_surname\", \n",
    "                         \"filipino\": \"name_and_surname\", \"indian\": \"surname\",\n",
    "                        \"japanese\": \"name_and_surname\"}\n",
    "        self.ethn_abbrs = {\"arabic\": \"ar\", \"italian\": \"it\", \"filipino\": \"ph\", \"indian\": \"in\", \"japanese\": \"jp\"}\n",
    "        \n",
    "        # make name and surname dictionaries by letter for required ethnicities\n",
    "        self.names = defaultdict(lambda: defaultdict(set))\n",
    "        self.surnames = defaultdict(lambda: defaultdict(set))\n",
    "    \n",
    "    def __create_ethnic_dicts(self):\n",
    "        \n",
    "        for ethnicity in self.ethnicity_list:\n",
    "            \n",
    "            if ethnicity in self.name_dict:\n",
    "                self.names[ethnicity] = {letter: {unidecode(w[\"name\"]) for w in self.name_dict[ethnicity] \n",
    "                                                 if w[\"name\"].isalpha() and unidecode(w[\"name\"][0]) == letter} for letter in ascii_lowercase}\n",
    "                \n",
    "            if ethnicity in self.surname_dict:\n",
    "                self.surnames[ethnicity] = {letter: {unidecode(w) for w in self.surname_dict[ethnicity] \n",
    "                                                 if w.isalpha() and unidecode(w)[0] == letter} for letter in ascii_lowercase}\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def clean_input(self):\n",
    "        \n",
    "        # replace separators with white spaces, then make sure there's only 1 white space is separating name parts\n",
    "        self.input_df.loc[:, \"full_name\"] = (self.input_df[\"full_name\"].apply(unidecode)\n",
    "                                                                .str.replace(re.compile(r\"[-'_()]\"), \" \")\n",
    "                                                                  .str.split().str.join(' '))\n",
    "\n",
    "        # only keep names that have parts consisting of letters and longer than a single character; places '' where no proper full names\n",
    "        self.input_df.loc[:, \"full_name\"] = self.input_df[\"full_name\"].apply(lambda _: \" \".join([p for p in _.split() \n",
    "                                                                                                 if p.isalpha() and len(p) > 1])).str.strip()\n",
    "        self.input_df = self.input_df.loc[self.input_df[\"full_name\"].apply(lambda x: isinstance(x, str) and len(str(x).strip()) > 0), :]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __search_surname(self, st):\n",
    "        \n",
    "        exmtch_s_ethns = []\n",
    "        \n",
    "        for ethnicity in self.ethnicity_list:\n",
    "            if ethnicity in self.surnames:\n",
    "                for name_prt in st.split():\n",
    "                    if name_prt in self.surnames[ethnicity][name_prt[0]]:\n",
    "                        exmtch_s_ethns.append(ethnicity) \n",
    "        \n",
    "        if (not exmtch_s_ethns):\n",
    "            for ethnicity in self.ethnicity_list:\n",
    "                if ethnicity in self.surname_ending_dict:\n",
    "                    for ending in self.surname_ending_dict[ethnicity]:\n",
    "                        for name_prt in st.split():\n",
    "                            if name_prt.endswith(ending) and (len(name_prt) - len(ending) > 1):\n",
    "                                exmtch_s_ethns.append(ethnicity)\n",
    "        \n",
    "        return \"|\".join(exmtch_s_ethns)\n",
    "            \n",
    "    \n",
    "    def find_ethnicity_candidates(self):\n",
    "   \n",
    "        self.__create_ethnic_dicts()\n",
    "    \n",
    "        self.input_df[\"n_ethn\"] = self.input_df[\"full_name\"].apply(lambda _: \"|\".join([ethnicity for ethnicity in self.ethnicity_list if 1 in \n",
    "                                                                      [1 for name_prt in _.split() if name_prt in self.names[ethnicity][name_prt[0]]]]))\n",
    "        \n",
    "        self.input_df[\"s_ethn\"] = self.input_df[\"full_name\"].apply(self.__search_surname)\n",
    "             \n",
    "        return self \n",
    "    \n",
    "    def pick_ethnicity(self):\n",
    "        \n",
    "        x_ethns = self.input_df[(self.input_df[\"n_ethn\"].str.len() > 1) | (self.input_df[\"s_ethn\"].str.len() > 1)]\n",
    "        \n",
    "        final_ethnicities = defaultdict(lambda: defaultdict(str))\n",
    "        \n",
    "        for row in x_ethns.iterrows():\n",
    "            customer_ethnicities = []\n",
    "            for ethnicity in self.ethnicity_list:\n",
    "                if self.deciders[ethnicity] == \"name\":\n",
    "                    if ethnicity in row[1].n_ethn:\n",
    "                        customer_ethnicities.append(ethnicity)\n",
    "                elif self.deciders[ethnicity] == \"surname\":\n",
    "                    if ethnicity in row[1].s_ethn:\n",
    "                        customer_ethnicities.append(ethnicity)\n",
    "                elif self.deciders[ethnicity] == \"name_and_surname\":\n",
    "                    if (ethnicity in row[1].s_ethn) and (ethnicity in row[1].n_ethn):\n",
    "                        customer_ethnicities.append(ethnicity)\n",
    "            customer_ethnicities = [self.ethn_abbrs[e] for e in customer_ethnicities]\n",
    "            final_ethnicities[row[1].cust_id] = {\"full_name\": row[1].full_name, \"ethnicity\" : \"|\".join(customer_ethnicities) if customer_ethnicities else None}\n",
    "                    \n",
    "        \n",
    "        self._detected_ethnicities = pd.DataFrame.from_dict(final_ethnicities, orient='index').dropna()\n",
    "        \n",
    "        print(Counter(self._detected_ethnicities[\"ethnicity\"]))\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'it': 1146, 'in': 1062, 'ar': 239, 'jp': 214, 'ph': 9, 'in|ar': 4, 'in|it': 1})\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/ik/Data/temp/sample_new_customer_names.csv\")\n",
    "ed = (EthnicityDetector(df, [\"indian\", \"filipino\", \"japanese\", \"arabic\", \"italian\"])\n",
    "                                                    .clean_input()).find_ethnicity_candidates().pick_ethnicity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   69551,    75466,   109753,   110550,   289934,   310349,\n",
       "              360719,   373870,   401322,   884081,\n",
       "            ...\n",
       "            23816680, 23817068, 23817502, 23817829, 23818501, 23818782,\n",
       "            23819400, 23820074, 23820609, 23821439],\n",
       "           dtype='int64', length=2675)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed._detected_ethnicities.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
